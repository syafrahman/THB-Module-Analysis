{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac53f6af-fccb-4553-a250-5062be62b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from gensim.models import fasttext\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_blobs\n",
    "from gensim.models import TfidfModel\n",
    "import gensim.corpora as corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9b43c73-214e-4ee0-95e2-e289d411589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"df_04.pkl\")\n",
    "pretrained_model_path = '../../../models/wva/cc.de.300.bin'\n",
    "\n",
    "tokenized_corpus = df['Words'].tolist()\n",
    "\n",
    "model = fasttext.load_facebook_model(pretrained_model_path)\n",
    "model.build_vocab(tokenized_corpus, update=True)\n",
    "model.train(tokenized_corpus, total_examples=len(tokenized_corpus), epochs=model.epochs)\n",
    "\n",
    "fine_tuned_model_path = '../../../models/wva/04/fine-tuned-model-04-04.bin'\n",
    "model.save(fine_tuned_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ea23d8-ad5c-4003-8cd6-d96532e515ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"df_04.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9523b4eb-8d75-42dd-815b-b48f933e7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "model = FastText.load('../../../models/wva/04/fine-tuned-model-04-04.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c2cd6f-2397-453b-b1b8-e087cfce73c6",
   "metadata": {},
   "source": [
    "<h1>Model Info: Vocabulary size: 2001998</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2e7e236-b8e7-4743-acfb-b5f7e808cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['ProcessedText']\n",
    "\n",
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = text.split()  # Split the text into words\n",
    "        final.append(new)\n",
    "    return final\n",
    "\n",
    "data_words = gen_words(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e27e859-64b3-4eca-a0f9-ed89bb3b80d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list_of_words = [word.lower() for sentence in data_words for word in sentence]\n",
    "unique_words_in_your_data = set(flat_list_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c9f104-8184-4449-a978-5f9b307bc68d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2> 1. Finding the Most Similar Word and Associated Titles in a Dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6baf0730-46b0-4448-8b02-72a76ad84a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar_filtered(word, model, your_vocab):\n",
    "    word = word.lower()\n",
    "    if word in your_vocab:\n",
    "        print(\"Exact word found in vocabulary.\")\n",
    "        similarity_score = model.wv.similarity(word, word)\n",
    "        print(f\"Similarity score of the word with itself: {similarity_score}\")\n",
    "    try:\n",
    "        all_similar_words = model.wv.most_similar(word, topn=50)\n",
    "        for similar_word, similarity in all_similar_words:\n",
    "            if similar_word.lower() in your_vocab:\n",
    "                return similar_word, similarity\n",
    "    except KeyError:\n",
    "        return \"The word is not in the model's vocabulary.\"\n",
    "\n",
    "    return \"No similar word found in your vocabulary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b7cd834-e73e-409f-9feb-0fec24c3cff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles_from_similar_words(similar_word, df):\n",
    "    print(f\"Searching for: '{similar_word}'\")\n",
    "    titles = []\n",
    "    similar_word_lower = similar_word.lower()\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        # Convert the text in 'ProcessedText' to lowercase before searching\n",
    "        if similar_word_lower in df.loc[i, 'ProcessedText'].lower():\n",
    "            title = df.loc[i, 'Title']\n",
    "            titles.append(title)\n",
    "\n",
    "    if not titles:\n",
    "        print(f\"No titles found for word: {similar_word}\")\n",
    "\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b8795405-a61d-47ab-9365-548b4d86a72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a word to find its most similar word:  finanzmodelle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar word: anwendungsmöglichkeiten, similarity score: 0.9947077631950378\n",
      "\n",
      "Searching for: 'anwendungsmöglichkeiten'\n",
      "\n",
      "Titles associated with the 'anwendungsmöglichkeiten':\n",
      "Modulkatalog Applied Computer Science Bachelor \n",
      "Modulkatalog Ingenieurwissenschaften Bachelor\n",
      "Modulkatalog Informatik Master\n",
      "Modulkatalog Energieeffizienz Techischer System Master\n",
      "Modulkatalog Digitale Medien Bachelor\n",
      "Modulkatalog Informatik Bachelor\n",
      "Modulkatalog Medieninformatik Master\n"
     ]
    }
   ],
   "source": [
    "word_to_check = input(\"Enter a word to find its most similar word: \")\n",
    "similar_word, similarity_score = find_most_similar_filtered(word_to_check, model, unique_words_in_your_data)\n",
    "\n",
    "print(f\"Most similar word: {similar_word}, similarity score: {similarity_score}\\n\")\n",
    "\n",
    "if similar_word not in [\"No similar word found in your vocabulary.\", f\"'{word_to_check}' is not in the vocabulary.\"]:\n",
    "    titles = get_titles_from_similar_words(similar_word, df)\n",
    "    print(f\"\\nTitles associated with the '{similar_word}':\")\n",
    "    print('\\n'.join(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1f992ab8-aff4-4c14-9f89-d0f8a348b0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a word to find its most similar word:  bayesian\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar word: bayessche, similarity score: 0.6543185114860535\n",
      "\n",
      "Searching for: 'bayessche'\n",
      "\n",
      "Titles associated with the 'bayessche':\n",
      "Modulkatalog Medizininformatik Bachelor\n",
      "Modulkatalog Informatik Master\n"
     ]
    }
   ],
   "source": [
    "word_to_check = input(\"Enter a word to find its most similar word: \")\n",
    "similar_word, similarity_score = find_most_similar_filtered(word_to_check, model, unique_words_in_your_data)\n",
    "\n",
    "print(f\"Most similar word: {similar_word}, similarity score: {similarity_score}\\n\")\n",
    "\n",
    "if similar_word not in [\"No similar word found in your vocabulary.\", f\"'{word_to_check}' is not in the vocabulary.\"]:\n",
    "    titles = get_titles_from_similar_words(similar_word, df)\n",
    "    print(f\"\\nTitles associated with the '{similar_word}':\")\n",
    "    print('\\n'.join(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "508cdee6-f91a-42dd-8bec-d9882ff03435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a word to find its most similar word:  luftraum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar word: energiebedarf, similarity score: 0.7440962791442871\n",
      "\n",
      "Searching for: 'energiebedarf'\n",
      "\n",
      "Titles associated with the 'energiebedarf':\n",
      "Modulkatalog Maschinenbau Bachelor\n",
      "Modulkatalog Wirtschaftsingenieurwesen Bachelor\n",
      "Modulkatalog Energieeffizienz Techischer System Master\n",
      "Modulkatalog Medieninformatik Master\n"
     ]
    }
   ],
   "source": [
    "word_to_check = input(\"Enter a word to find its most similar word: \")\n",
    "similar_word, similarity_score = find_most_similar_filtered(word_to_check, model, unique_words_in_your_data)\n",
    "\n",
    "print(f\"Most similar word: {similar_word}, similarity score: {similarity_score}\\n\")\n",
    "\n",
    "if similar_word not in [\"No similar word found in your vocabulary.\", f\"'{word_to_check}' is not in the vocabulary.\"]:\n",
    "    titles = get_titles_from_similar_words(similar_word, df)\n",
    "    print(f\"\\nTitles associated with the '{similar_word}':\")\n",
    "    print('\\n'.join(titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7296198c-e408-4f7d-ac32-e01120fd743d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>4. Semantic Clustering of Words Using K-Means</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a532bfb3-bd97-4a97-9cf9-56f8cc87e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df['Words']\n",
    "\n",
    "flat_list_of_words = [word.lower() for sentence in words for word in sentence]\n",
    "unique_words_in_your_data = set(flat_list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2f92d1d-a12a-49be-9aa6-c922c6f1ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(words)\n",
    "\n",
    "# Convert documents to vectors (corpus)\n",
    "corpus = [id2word.doc2bow(text) for text in words]\n",
    "\n",
    "# Create a TF-IDF model\n",
    "tfidf = TfidfModel(corpus, id2word=id2word)\n",
    "\n",
    "# Define the threshold for low-value words\n",
    "low_value = 0.03\n",
    "\n",
    "# Initialize lists to track words\n",
    "words = []\n",
    "words_missing_in_tfidf = []\n",
    "\n",
    "# Iterate through each document in the corpus\n",
    "for i in range(len(corpus)):\n",
    "    bow = corpus[i]\n",
    "    \n",
    "    # Identify low-value words (below the threshold)\n",
    "    low_value_words = [id for id, value in tfidf[bow] if value < low_value]\n",
    "    \n",
    "    # Update the list of words to remove\n",
    "    for item in low_value_words:\n",
    "        words.append(id2word[item])\n",
    "    \n",
    "    # Identify words with a TF-IDF score of 0\n",
    "    tfidf_ids = set(id for id, value in tfidf[bow])\n",
    "    bow_ids = set(id for id, value in bow)\n",
    "    words_missing_in_tfidf = [id2word[id] for id in bow_ids if id not in tfidf_ids]\n",
    "\n",
    "    # Combine lists of words to remove\n",
    "    drops = set(low_value_words + words_missing_in_tfidf)\n",
    "\n",
    "    # Create a new bow for the document, excluding the words to remove\n",
    "    new_bow = [b for b in bow if b[0] not in drops]\n",
    "    corpus[i] = new_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51825d73-2248-4478-a11e-d0cce478fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ids = [word_id for doc in corpus for (word_id, value) in doc]\n",
    "\n",
    "unique_words_after_tfidf = set([id2word[word_id] for word_id in word_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207eeed0-22b8-4b41-8ff3-070345385afe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retrieve vectors for each word in the vocabulary\n",
    "word_vectors = [model.wv[word] for word in unique_words_after_tfidf if word in model.wv]\n",
    "\n",
    "# Corresponding words for each vector\n",
    "words = [word for word in unique_words_after_tfidf if word in model.wv]\n",
    "\n",
    "# Apply K-means clustering\n",
    "num_clusters = 10  # Adjust the number of clusters as needed\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "kmeans.fit(word_vectors)\n",
    "\n",
    "# Getting the cluster labels for each word vector\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Grouping words by their clusters\n",
    "word_clusters = {}\n",
    "for word, cluster in zip(words, labels):\n",
    "    if cluster not in word_clusters:\n",
    "        word_clusters[cluster] = []\n",
    "    word_clusters[cluster].append(word)\n",
    "\n",
    "# Display the words in each cluster\n",
    "for cluster in range(num_clusters):\n",
    "    print(f\"Cluster {cluster}: {word_clusters[cluster]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb675782-886d-4d51-bd8a-5393b76ddcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'word_clusters.txt'\n",
    "with open(file_path, 'w') as f:\n",
    "    for cluster, words in word_clusters.items():\n",
    "        f.write(f'Cluster {cluster}: {\", \".join(words)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9922b139-efc7-452d-87fc-9bbeef974ce7",
   "metadata": {},
   "source": [
    "<h3>PCA Plots</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c41eb9-d3eb-4553-b58f-e15621af94d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce word vectors to 2D using PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "reduced_vectors = pca.fit_transform(word_vectors)\n",
    "\n",
    "# Plotting each word in the 2D space\n",
    "plt.figure(figsize=(15, 10))\n",
    "colors = plt.cm.get_cmap('viridis', num_clusters)\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    plt.scatter(reduced_vectors[i, 0], reduced_vectors[i, 1], color=colors(labels[i]), label=labels[i])\n",
    "    plt.annotate(word, xy=(reduced_vectors[i, 0], reduced_vectors[i, 1]), xytext=(5, 2),\n",
    "                 textcoords='offset points', ha='right', va='bottom')\n",
    "\n",
    "# Adding a legend and titles\n",
    "plt.title('Word Clusters Visualized in 2D using PCA')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.savefig('word_clusters.png', dpi=300)  # Save as PNG with high dpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1853f50-0d2e-49f6-870f-36af4eef5aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "colors = plt.cm.get_cmap('tab10', num_clusters)  # Using tab10 colormap for better contrast\n",
    "\n",
    "# Plot the centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], marker='x', s=100, color='black', label='Centroids')\n",
    "\n",
    "# Plot each word in the 2D space with semi-transparency\n",
    "for i, word in enumerate(words):\n",
    "    plt.scatter(reduced_vectors[i, 0], reduced_vectors[i, 1],\n",
    "                color=colors(labels[i]), alpha=0.7, s=50)  # Semi-transparent and larger dots\n",
    "\n",
    "# You could either annotate just the centroids or remove annotations to reduce clutter\n",
    "# for i, word in enumerate(words):\n",
    "#     plt.annotate(word, xy=(reduced_vectors[i, 0], reduced_vectors[i, 1]), xytext=(5, 2),\n",
    "#                  textcoords='offset points', ha='right', va='bottom')\n",
    "\n",
    "plt.title('Word Clusters Visualized in 2D using PCA')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.grid(True)\n",
    "# plt.legend()  # Uncomment if the legend is useful, otherwise leave it out to reduce clutter\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('word_clusters_without_word_and_legend.png', dpi=300)  # Save as PNG with high dpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffea284-e871-47c5-b96b-5b0f2cb48f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Create a color map based on the number of clusters\n",
    "colors = plt.cm.get_cmap('tab10', num_clusters)\n",
    "\n",
    "# Plot each cluster with a unique color and add a label for the legend\n",
    "for cluster_num in range(num_clusters):\n",
    "    # Find the indices of the points in this cluster\n",
    "    cluster_indices = np.where(labels == cluster_num)[0]\n",
    "    # Select the points that belong to the current cluster\n",
    "    cluster_points = reduced_vectors[cluster_indices]\n",
    "    # Plot the points with the cluster-specific color and label\n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "                color=colors(cluster_num), \n",
    "                alpha=0.7, s=50, \n",
    "                label=f'Cluster {cluster_num}')\n",
    "\n",
    "plt.title('Word Clusters Visualized in 2D using PCA')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.grid(True)\n",
    "plt.legend()  # Display the legend\n",
    "plt.savefig('word_clusters_without_word_with_legend.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcc1f54-0037-474f-86fb-6dc61265a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "pca = PCA(n_components=2)\n",
    "reduced_vectors = pca.fit_transform(word_vectors)\n",
    "\n",
    "# Create a DataFrame for the plot\n",
    "df = pd.DataFrame(reduced_vectors, columns=['PCA1', 'PCA2'])\n",
    "df['word'] = words\n",
    "df['cluster'] = labels\n",
    "\n",
    "# Plot using Plotly\n",
    "fig = px.scatter(df, x='PCA1', y='PCA2', color='cluster', text='word', title='Word Clusters Visualized in 2D using PCA')\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.update_layout(showlegend=True)\n",
    "fig.update_layout(legend_title_text='Cluster')\n",
    "\n",
    "# Save the interactive plot as an HTML file\n",
    "fig.write_html('word_clusters.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
